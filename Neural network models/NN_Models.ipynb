{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN-Models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXqRKw6cBJNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !git clone https://github.com/KodeWil/final_project_AI_csv_Data.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tqCXs-QyJKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dependencies\n",
        "# %reset\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense# Neural network\n",
        "import pandas as pd \n",
        "import glob \n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import copy\n",
        "from google.colab import files as fl\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import neural_network\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkfC2JCgBiKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def addData(files: str) -> list:\n",
        "    allCsv = []\n",
        "    for file in files:\n",
        "      temp = open(file)\n",
        "      tempDf = pd.read_csv(file)\n",
        "      allCsv.append(tempDf)\n",
        "    return allCsv\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8vk9-1prLxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def printAll(df):\n",
        "  pd.set_option('display.max_rows', None)\n",
        "  print(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPLkK4OkBnOH",
        "colab_type": "code",
        "outputId": "0e874845-f2ba-4bfb-b808-80d6b87937a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "frames = []\n",
        "\n",
        "#Create a list ('frames') with four nested lists, one per sensor. \n",
        "#Each nested list have all the samples (DF) for that sensor.\n",
        "%cd /content/final_project_AI_csv_Data/phone/accel\n",
        "files = glob.glob('*.csv')\n",
        "files.sort()\n",
        "frames.append(addData(files))\n",
        "%cd /content/final_project_AI_csv_Data/phone/gyro\n",
        "files = glob.glob('*.csv')\n",
        "files.sort()\n",
        "frames.append(addData(files))\n",
        "%cd /content/final_project_AI_csv_Data/watch/accel\n",
        "files = glob.glob('*.csv')\n",
        "files.sort()\n",
        "frames.append(addData(files))\n",
        "%cd /content/final_project_AI_csv_Data/watch/gyro\n",
        "files = glob.glob('*.csv')\n",
        "files.sort()\n",
        "frames.append(addData(files))\n",
        "print(len(frames))\n",
        "# 0 in frames = /phone/accel\n",
        "# 1 in frames = /phone/gyro\n",
        "# 2 in frames = /watch/accel\n",
        "# 3 in frames = /watch/gyro"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/final_project_AI_csv_Data/phone/accel\n",
            "/content/final_project_AI_csv_Data/phone/gyro\n",
            "/content/final_project_AI_csv_Data/watch/accel\n",
            "/content/final_project_AI_csv_Data/watch/gyro\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orlmj0Bh3vQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cutSamples(frames1, frames2):\n",
        "  for i in range (0,50):\n",
        "    samples1 = frames1[i].shape[0]\n",
        "    samples2 = frames2[i].shape[0]\n",
        "    if(samples1 > samples2):\n",
        "      toDrop = list(range(samples2, samples1))\n",
        "      frames1[i].drop(frames1[i].index[[toDrop]], inplace = True)\n",
        "    elif(samples2 > samples1):\n",
        "      toDrop = list(range(samples1, samples2))\n",
        "      frames2[i].drop(frames2[i].index[[toDrop]], inplace = True) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Muo2VDcleOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kerasSequiential(X, y):\n",
        "  InpDim = X.shape[1]\n",
        "  model = Sequential()\n",
        "  model.add(Dense(int(InpDim*2), input_dim=InpDim, activation=\"relu\"))\n",
        "  model.add(Dense(64, activation=\"relu\"))\n",
        "  model.add(Dense(18, activation=\"softmax\"))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  history = model.fit(X, y, epochs=30, batch_size=20, verbose=0)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24ySOtTEJ4G1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mlpNN(Xt, yt, Xte, yte):\n",
        "  # activTypes = [\"logistic\", \"tanh\", \"relu\"]\n",
        "  # solverTypes = [\"lbfgs\", \"sgd\", \"adam\"]\n",
        "  activTypes = [\"relu\"]\n",
        "  solverTypes = [\"adam\"]\n",
        "  allModels = []\n",
        "  for activType in activTypes:\n",
        "    for solverType in solverTypes:\n",
        "      clf = neural_network.MLPClassifier(\n",
        "          hidden_layer_sizes = [100,64,18],\n",
        "          activation = activType,\n",
        "          solver = solverType,\n",
        "          alpha = 0.0001, # regularización, para la generalización del clasificador\n",
        "          batch_size = 'auto',\n",
        "          learning_rate_init = 0.001,\n",
        "          power_t = 0.5,\n",
        "          max_iter = 300,\n",
        "          shuffle = True,\n",
        "          verbose = False\n",
        "          )\n",
        "      allModels.append((clf, activType, solverType))\n",
        "  best = 0\n",
        "  bestIndex = -1\n",
        "  for i, mlpModel in enumerate(allModels):\n",
        "    mlpModel[0].fit(Xt, yt)\n",
        "    y_predicho = mlpModel[0].predict(Xte)\n",
        "    tempScore = accuracy_score(yte,y_predicho)\n",
        "    if(tempScore > best):\n",
        "      best = tempScore\n",
        "      bestIndex = i\n",
        "  activ = allModels[i][1]\n",
        "  solve = allModels[i][2]\n",
        "  print(\"\")\n",
        "  print(\"Scikit learn multilayer perceptron\")\n",
        "  print(\"\")\n",
        "  print(\"El mejor modelo con mlp scikit learn utiliza como parametro de activacion \" + activ + \" como solver utiliza \" + solve + \" y su puntaje de acierto es: \"+ str(best))\n",
        "  print(\"\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip3zLapcEi03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Split into train and test data, encode \"ACTIVITY\" column into a numerical column\n",
        "def dataTransformation(frame, columns: bool):\n",
        "  ohe = OneHotEncoder()\n",
        "  sc = StandardScaler()\n",
        "  if(columns):\n",
        "    y = frame[\"ACTIVITY\"]\n",
        "    X = frame.drop(columns = [\"ACTIVITY\", \"class\"])\n",
        "    X = X.values\n",
        "    X = sc.fit_transform(X)\n",
        "    y = y.values\n",
        "    y = y.reshape(-1,1)\n",
        "    y = ohe.fit_transform(y).toarray()\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "    return (kerasSequiential(X_train, y_train), X_test, y_test)\n",
        "  else:\n",
        "    y = frame[0]\n",
        "    y = y.values\n",
        "    y = y.reshape(-1,1)\n",
        "    y = ohe.fit_transform(y).toarray()\n",
        "    X = frame.drop(columns = [0,91,93,182])\n",
        "    X = X.values\n",
        "    X = sc.fit_transform(X)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "    mlpNN(X_train, y_train, X_test, y_test)\n",
        "    return (kerasSequiential(X_train, y_train), X_test, y_test)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP0Z_SJEBvmf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "outputId": "20682b30-c328-4a44-ba55-55344794449d"
      },
      "source": [
        "# Concatenate all phone Dataframes in a single One\n",
        "sensors = []\n",
        "phoneAccel = pd.concat(frames[0])\n",
        "sensors.append(phoneAccel)\n",
        "phoneGyro = pd.concat(frames[1])\n",
        "sensors.append(phoneGyro)\n",
        "watchAccel = pd.concat(frames[2])\n",
        "sensors.append(watchAccel)\n",
        "watchGyro = pd.concat(frames[3])\n",
        "sensors.append(watchGyro)\n",
        "\n",
        "\n",
        "#Cut samples to match with the number of samples in the other sensor (accel and gyro)\n",
        "cutSamples(frames[0], frames[1]) #Phone sensors\n",
        "cutSamples(frames[2], frames[3]) #Watch sensors\n",
        "\n",
        "#Concat all individual samples for a single sensor in one data frame. \n",
        "phoneAccel = pd.concat(frames[0], ignore_index=True)\n",
        "phoneGyro = pd.concat(frames[1], ignore_index=True)\n",
        "watchAccel = pd.concat(frames[2], ignore_index=True)\n",
        "watchGyro = pd.concat(frames[3], ignore_index=True)\n",
        "\n",
        "#Create a new data frame with both sensors for both devices.\n",
        "phone = pd.concat([phoneAccel, phoneGyro], ignore_index=True, axis = 1)\n",
        "phoneIndex = phone[phone[0] != phone[93]].index\n",
        "phone.drop(phoneIndex, inplace=True)\n",
        "watch = pd.concat([watchAccel, watchGyro], ignore_index=True, axis = 1)\n",
        "watchIndex = watch[watch[0] != watch[93]].index\n",
        "watch.drop(watchIndex, inplace=True)\n",
        "\n",
        "models = []\n",
        "# for sensor in sensors:\n",
        "#   models.append(dataTransformation(sensor, True))\n",
        "print(\"\")\n",
        "print(\"Phone merged sensors accuracy\")\n",
        "print(\"\")\n",
        "models.append(dataTransformation(phone, False))\n",
        "print(\"\")\n",
        "print(\"Watch merged sensors accuracy\")\n",
        "print(\"\")\n",
        "models.append(dataTransformation(watch, False))\n",
        "\n",
        "# names = [\"Phone Accel\", \"Phone Gyro\" , \"Watch Accel\", \"Watch Gyro\", \"Phone\", \"Watch\" ]\n",
        "# print(\"\")\n",
        "print(\"Models' scores\")\n",
        "print(\"\")\n",
        "\n",
        "for i, model in  enumerate(models):\n",
        "  score, acc = model[0].evaluate(model[1], model[2],\n",
        "                            batch_size=20)\n",
        "  print(\"\")\n",
        "  print(\"The accuracy for \" + names[i]+ \" is: \" + str(acc))\n",
        "  print(\"\")\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py:3940: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  result = getitem(key)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Phone merged sensors accuracy\n",
            "\n",
            "\n",
            "Scikit learn multilayer perceptron\n",
            "\n",
            "El mejor modelo con mlp scikit learn utiliza como parametro de activacion relu como solver utiliza adam y su puntaje de acierto es: 0.7764763299170327\n",
            "\n",
            "\n",
            "Phone merged sensors accuracy\n",
            "\n",
            "\n",
            "Scikit learn multilayer perceptron\n",
            "\n",
            "El mejor modelo con mlp scikit learn utiliza como parametro de activacion relu como solver utiliza adam y su puntaje de acierto es: 0.8125207022192779\n",
            "\n",
            "Models' scores\n",
            "\n",
            "2049/2049 [==============================] - 0s 47us/step\n",
            "\n",
            "The accuracy for Phone Accel is: 0.8501707911491394\n",
            "\n",
            "3019/3019 [==============================] - 0s 45us/step\n",
            "\n",
            "The accuracy for Phone Gyro is: 0.8675057888031006\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}