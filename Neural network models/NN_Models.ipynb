{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN-Models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXqRKw6cBJNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/KodeWil/final_project_AI_csv_Data.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tqCXs-QyJKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dependencies\n",
        "# %reset\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense# Neural network\n",
        "import pandas as pd \n",
        "import glob \n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import copy\n",
        "from google.colab import files as fl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkfC2JCgBiKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def addData(files: str) -> list:\n",
        "    allCsv = []\n",
        "    for file in files:\n",
        "      temp = open(file)\n",
        "      tempDf = pd.read_csv(file)\n",
        "      allCsv.append(tempDf)\n",
        "    return allCsv\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8vk9-1prLxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def printAll(df):\n",
        "  pd.set_option('display.max_rows', None)\n",
        "  print(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPLkK4OkBnOH",
        "colab_type": "code",
        "outputId": "6c722c0d-2dfa-4b50-ebbb-a6233ecfb30b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "frames = []\n",
        "\n",
        "#Create a list ('frames') with four nested lists, one per sensor. \n",
        "#Each nested list have all the samples (DF) for that sensor.\n",
        "%cd /content/final_project_AI_csv_Data/phone/accel\n",
        "files = glob.glob('*.csv')\n",
        "files.sort()\n",
        "frames.append(addData(files))\n",
        "%cd /content/final_project_AI_csv_Data/phone/gyro\n",
        "files = glob.glob('*.csv')\n",
        "files.sort()\n",
        "frames.append(addData(files))\n",
        "%cd /content/final_project_AI_csv_Data/watch/accel\n",
        "files = glob.glob('*.csv')\n",
        "files.sort()\n",
        "frames.append(addData(files))\n",
        "%cd /content/final_project_AI_csv_Data/watch/gyro\n",
        "files = glob.glob('*.csv')\n",
        "files.sort()\n",
        "frames.append(addData(files))\n",
        "print(len(frames))\n",
        "# 0 in frames = /phone/accel\n",
        "# 1 in frames = /phone/gyro\n",
        "# 2 in frames = /watch/accel\n",
        "# 3 in frames = /watch/gyro"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/final_project_AI_csv_Data/phone/accel\n",
            "/content/final_project_AI_csv_Data/phone/gyro\n",
            "/content/final_project_AI_csv_Data/watch/accel\n",
            "/content/final_project_AI_csv_Data/watch/gyro\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orlmj0Bh3vQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cutSamples(frames1, frames2):\n",
        "  for i in range (0,50):\n",
        "    samples1 = frames1[i].shape[0]\n",
        "    samples2 = frames2[i].shape[0]\n",
        "    if(samples1 > samples2):\n",
        "      toDrop = list(range(samples2, samples1))\n",
        "      frames1[i].drop(frames1[i].index[[toDrop]], inplace = True)\n",
        "    elif(samples2 > samples1):\n",
        "      toDrop = list(range(samples1, samples2))\n",
        "      frames2[i].drop(frames2[i].index[[toDrop]], inplace = True) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Muo2VDcleOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kerasSequiential(X, y):\n",
        "  InpDim = X.shape[1]\n",
        "  model = Sequential()\n",
        "  model.add(Dense(int(InpDim*2), input_dim=InpDim, activation=\"relu\"))\n",
        "  model.add(Dense(64, activation=\"relu\"))\n",
        "  model.add(Dense(18, activation=\"softmax\"))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  history = model.fit(X, y, epochs=30, batch_size=20)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip3zLapcEi03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Split into train and test data, encode \"ACTIVITY\" column into a numerical column\n",
        "def dataTransformation(frame, columns: bool):\n",
        "  ohe = OneHotEncoder()\n",
        "  sc = StandardScaler()\n",
        "  if(columns):\n",
        "    y = frame[\"ACTIVITY\"]\n",
        "    X = frame.drop(columns = [\"ACTIVITY\", \"class\"])\n",
        "    X = X.values\n",
        "    X = sc.fit_transform(X)\n",
        "    y = y.values\n",
        "    y = y.reshape(-1,1)\n",
        "    y = ohe.fit_transform(y).toarray()\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "    return (kerasSequiential(X_train, y_train), X_test, y_test)\n",
        "  else:\n",
        "    y = frame[0]\n",
        "    y = y.values\n",
        "    y = y.reshape(-1,1)\n",
        "    y = ohe.fit_transform(y).toarray()\n",
        "    X = frame.drop(columns = [0,91,93,182])\n",
        "    X = X.values\n",
        "    X = sc.fit_transform(X)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "    return (kerasSequiential(X_train, y_train), X_test, y_test)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP0Z_SJEBvmf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "114d7a1a-a5d5-4a57-ae00-31124df675fc"
      },
      "source": [
        "# Concatenate all phone Dataframes in a single One\n",
        "sensors = []\n",
        "phoneAccel = pd.concat(frames[0])\n",
        "sensors.append(phoneAccel)\n",
        "phoneGyro = pd.concat(frames[1])\n",
        "sensors.append(phoneGyro)\n",
        "watchAccel = pd.concat(frames[2])\n",
        "sensors.append(watchAccel)\n",
        "watchGyro = pd.concat(frames[3])\n",
        "sensors.append(watchGyro)\n",
        "\n",
        "\n",
        "#Cut samples to match with the number of samples in the other sensor (accel and gyro)\n",
        "cutSamples(frames[0], frames[1]) #Phone sensors\n",
        "cutSamples(frames[2], frames[3]) #Watch sensors\n",
        "\n",
        "#Concat all individual samples for a single sensor in one data frame. \n",
        "phoneAccel = pd.concat(frames[0], ignore_index=True)\n",
        "phoneGyro = pd.concat(frames[1], ignore_index=True)\n",
        "watchAccel = pd.concat(frames[2], ignore_index=True)\n",
        "watchGyro = pd.concat(frames[3], ignore_index=True)\n",
        "\n",
        "#Create a new data frame with both sensors for both devices.\n",
        "phone = pd.concat([phoneAccel, phoneGyro], ignore_index=True, axis = 1)\n",
        "phoneIndex = phone[phone[0] != phone[93]].index\n",
        "phone.drop(phoneIndex, inplace=True)\n",
        "watch = pd.concat([watchAccel, watchGyro], ignore_index=True, axis = 1)\n",
        "watchIndex = watch[watch[0] != watch[93]].index\n",
        "watch.drop(watchIndex, inplace=True)\n",
        "\n",
        "models = []\n",
        "for sensor in sensors:\n",
        "  models.append(dataTransformation(sensor, True))\n",
        "\n",
        "models.append(dataTransformation(phone, False))\n",
        "models.append(dataTransformation(watch, False))\n",
        "\n",
        "names = [\"Phone Accel\", \"Phone Gyro\" , \"Watch Accel\", \"Watch Gyro\", \"Phone\", \"Watch\" ]\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"Models' scores\")\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n",
        "for i, model in  enumerate(models):\n",
        "  score, acc = model[0].evaluate(model[1], model[2],\n",
        "                            batch_size=20)\n",
        "  print(\"\")\n",
        "  print(\"The accuracy for \" + names[i]+ \" is: \" + str(acc))\n",
        "  print(\"\")\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "12096/12096 [==============================] - 1s 70us/step - loss: 1.7053 - accuracy: 0.4334\n",
            "Epoch 2/30\n",
            "12096/12096 [==============================] - 1s 64us/step - loss: 1.2320 - accuracy: 0.5899\n",
            "Epoch 3/30\n",
            "12096/12096 [==============================] - 1s 73us/step - loss: 1.0370 - accuracy: 0.6577\n",
            "Epoch 4/30\n",
            "12096/12096 [==============================] - 1s 66us/step - loss: 0.9023 - accuracy: 0.7044\n",
            "Epoch 5/30\n",
            "12096/12096 [==============================] - 1s 63us/step - loss: 0.8129 - accuracy: 0.7309\n",
            "Epoch 6/30\n",
            "12096/12096 [==============================] - 1s 63us/step - loss: 0.7464 - accuracy: 0.7581\n",
            "Epoch 7/30\n",
            "12096/12096 [==============================] - 1s 63us/step - loss: 0.6945 - accuracy: 0.7707\n",
            "Epoch 8/30\n",
            "12096/12096 [==============================] - 1s 64us/step - loss: 0.6515 - accuracy: 0.7865\n",
            "Epoch 9/30\n",
            "12096/12096 [==============================] - 1s 62us/step - loss: 0.6007 - accuracy: 0.7995\n",
            "Epoch 10/30\n",
            "12096/12096 [==============================] - 1s 65us/step - loss: 0.5760 - accuracy: 0.8067\n",
            "Epoch 11/30\n",
            "12096/12096 [==============================] - 1s 63us/step - loss: 0.5456 - accuracy: 0.8170\n",
            "Epoch 12/30\n",
            "12096/12096 [==============================] - 1s 65us/step - loss: 0.5100 - accuracy: 0.8274\n",
            "Epoch 13/30\n",
            "12096/12096 [==============================] - 1s 71us/step - loss: 0.4892 - accuracy: 0.8366\n",
            "Epoch 14/30\n",
            "12096/12096 [==============================] - 1s 68us/step - loss: 0.4694 - accuracy: 0.8421\n",
            "Epoch 15/30\n",
            "12096/12096 [==============================] - 1s 65us/step - loss: 0.4486 - accuracy: 0.8480\n",
            "Epoch 16/30\n",
            "12096/12096 [==============================] - 1s 71us/step - loss: 0.4341 - accuracy: 0.8511\n",
            "Epoch 17/30\n",
            "12096/12096 [==============================] - 1s 77us/step - loss: 0.4181 - accuracy: 0.8571\n",
            "Epoch 18/30\n",
            "12096/12096 [==============================] - 1s 78us/step - loss: 0.3957 - accuracy: 0.8652\n",
            "Epoch 19/30\n",
            "12096/12096 [==============================] - 1s 76us/step - loss: 0.3839 - accuracy: 0.8701\n",
            "Epoch 20/30\n",
            "12096/12096 [==============================] - 1s 69us/step - loss: 0.3659 - accuracy: 0.8765\n",
            "Epoch 21/30\n",
            "12096/12096 [==============================] - 1s 68us/step - loss: 0.3588 - accuracy: 0.8793\n",
            "Epoch 22/30\n",
            "12096/12096 [==============================] - 1s 67us/step - loss: 0.3380 - accuracy: 0.8872\n",
            "Epoch 23/30\n",
            "12096/12096 [==============================] - 1s 66us/step - loss: 0.3269 - accuracy: 0.8878\n",
            "Epoch 24/30\n",
            "12096/12096 [==============================] - 1s 67us/step - loss: 0.3252 - accuracy: 0.8891\n",
            "Epoch 25/30\n",
            "12096/12096 [==============================] - 1s 79us/step - loss: 0.3105 - accuracy: 0.8946\n",
            "Epoch 26/30\n",
            "12096/12096 [==============================] - 1s 69us/step - loss: 0.3072 - accuracy: 0.8957\n",
            "Epoch 27/30\n",
            "12096/12096 [==============================] - 1s 67us/step - loss: 0.2912 - accuracy: 0.9007\n",
            "Epoch 28/30\n",
            "12096/12096 [==============================] - 1s 69us/step - loss: 0.2884 - accuracy: 0.9026\n",
            "Epoch 29/30\n",
            "12096/12096 [==============================] - 1s 69us/step - loss: 0.2735 - accuracy: 0.9090\n",
            "Epoch 30/30\n",
            "12096/12096 [==============================] - 1s 72us/step - loss: 0.2897 - accuracy: 0.9039\n",
            "\n",
            "\n",
            "\n",
            "Epoch 1/30\n",
            "12096/12096 [==============================] - 1s 70us/step - loss: 2.2185 - accuracy: 0.2426\n",
            "Epoch 2/30\n",
            "12096/12096 [==============================] - 1s 65us/step - loss: 1.9794 - accuracy: 0.3211\n",
            "Epoch 3/30\n",
            "12096/12096 [==============================] - 1s 70us/step - loss: 1.8643 - accuracy: 0.3603\n",
            "Epoch 4/30\n",
            "12096/12096 [==============================] - 1s 64us/step - loss: 1.7807 - accuracy: 0.3859\n",
            "Epoch 5/30\n",
            "12096/12096 [==============================] - 1s 64us/step - loss: 1.7159 - accuracy: 0.4136\n",
            "Epoch 6/30\n",
            "12096/12096 [==============================] - 1s 64us/step - loss: 1.6646 - accuracy: 0.4349\n",
            "Epoch 7/30\n",
            "12096/12096 [==============================] - 1s 66us/step - loss: 1.6218 - accuracy: 0.4467\n",
            "Epoch 8/30\n",
            "12096/12096 [==============================] - 1s 67us/step - loss: 1.5743 - accuracy: 0.4673\n",
            "Epoch 9/30\n",
            "12096/12096 [==============================] - 1s 65us/step - loss: 1.5386 - accuracy: 0.4776\n",
            "Epoch 10/30\n",
            "12096/12096 [==============================] - 1s 70us/step - loss: 1.5036 - accuracy: 0.4896\n",
            "Epoch 11/30\n",
            "12096/12096 [==============================] - 1s 72us/step - loss: 1.4695 - accuracy: 0.5001\n",
            "Epoch 12/30\n",
            "12096/12096 [==============================] - 1s 70us/step - loss: 1.4458 - accuracy: 0.5074\n",
            "Epoch 13/30\n",
            "12096/12096 [==============================] - 1s 66us/step - loss: 1.4143 - accuracy: 0.5217\n",
            "Epoch 14/30\n",
            "12096/12096 [==============================] - 1s 65us/step - loss: 1.3834 - accuracy: 0.5317\n",
            "Epoch 15/30\n",
            "12096/12096 [==============================] - 1s 71us/step - loss: 1.3657 - accuracy: 0.5394\n",
            "Epoch 16/30\n",
            "12096/12096 [==============================] - 1s 67us/step - loss: 1.3388 - accuracy: 0.5458\n",
            "Epoch 17/30\n",
            "12096/12096 [==============================] - 1s 65us/step - loss: 1.3112 - accuracy: 0.5537\n",
            "Epoch 18/30\n",
            "12096/12096 [==============================] - 1s 66us/step - loss: 1.2927 - accuracy: 0.5622\n",
            "Epoch 19/30\n",
            "12096/12096 [==============================] - 1s 67us/step - loss: 1.2709 - accuracy: 0.5707\n",
            "Epoch 20/30\n",
            "12096/12096 [==============================] - 1s 65us/step - loss: 1.2503 - accuracy: 0.5769\n",
            "Epoch 21/30\n",
            "12096/12096 [==============================] - 1s 67us/step - loss: 1.2391 - accuracy: 0.5825\n",
            "Epoch 22/30\n",
            "12096/12096 [==============================] - 1s 73us/step - loss: 1.2072 - accuracy: 0.5961\n",
            "Epoch 23/30\n",
            "12096/12096 [==============================] - 1s 71us/step - loss: 1.1936 - accuracy: 0.5981\n",
            "Epoch 24/30\n",
            "12096/12096 [==============================] - 1s 71us/step - loss: 1.1831 - accuracy: 0.6068\n",
            "Epoch 25/30\n",
            "12096/12096 [==============================] - 1s 72us/step - loss: 1.1699 - accuracy: 0.6076\n",
            "Epoch 26/30\n",
            "12096/12096 [==============================] - 1s 71us/step - loss: 1.1473 - accuracy: 0.6139\n",
            "Epoch 27/30\n",
            "12096/12096 [==============================] - 1s 71us/step - loss: 1.1359 - accuracy: 0.6153\n",
            "Epoch 28/30\n",
            "12096/12096 [==============================] - 1s 71us/step - loss: 1.1197 - accuracy: 0.6226\n",
            "Epoch 29/30\n",
            "12096/12096 [==============================] - 1s 66us/step - loss: 1.1094 - accuracy: 0.6250\n",
            "Epoch 30/30\n",
            "12096/12096 [==============================] - 1s 64us/step - loss: 1.0988 - accuracy: 0.6321\n",
            "\n",
            "\n",
            "\n",
            "Epoch 1/30\n",
            "11573/11573 [==============================] - 1s 70us/step - loss: 1.1990 - accuracy: 0.6232\n",
            "Epoch 2/30\n",
            "11573/11573 [==============================] - 1s 63us/step - loss: 0.7934 - accuracy: 0.7412\n",
            "Epoch 3/30\n",
            "11573/11573 [==============================] - 1s 66us/step - loss: 0.6782 - accuracy: 0.7787\n",
            "Epoch 4/30\n",
            "11573/11573 [==============================] - 1s 66us/step - loss: 0.6205 - accuracy: 0.7992\n",
            "Epoch 5/30\n",
            "11573/11573 [==============================] - 1s 66us/step - loss: 0.5694 - accuracy: 0.8163\n",
            "Epoch 6/30\n",
            "11573/11573 [==============================] - 1s 64us/step - loss: 0.5315 - accuracy: 0.8277\n",
            "Epoch 7/30\n",
            "11573/11573 [==============================] - 1s 69us/step - loss: 0.5009 - accuracy: 0.8366\n",
            "Epoch 8/30\n",
            "11573/11573 [==============================] - 1s 64us/step - loss: 0.4766 - accuracy: 0.8441\n",
            "Epoch 9/30\n",
            "11573/11573 [==============================] - 1s 67us/step - loss: 0.4510 - accuracy: 0.8512\n",
            "Epoch 10/30\n",
            "11573/11573 [==============================] - 1s 68us/step - loss: 0.4314 - accuracy: 0.8597\n",
            "Epoch 11/30\n",
            "11573/11573 [==============================] - 1s 64us/step - loss: 0.4115 - accuracy: 0.8646\n",
            "Epoch 12/30\n",
            "11573/11573 [==============================] - 1s 63us/step - loss: 0.3923 - accuracy: 0.8714\n",
            "Epoch 13/30\n",
            "11573/11573 [==============================] - 1s 63us/step - loss: 0.3716 - accuracy: 0.8777\n",
            "Epoch 14/30\n",
            "11573/11573 [==============================] - 1s 64us/step - loss: 0.3667 - accuracy: 0.8749\n",
            "Epoch 15/30\n",
            "11573/11573 [==============================] - 1s 70us/step - loss: 0.3520 - accuracy: 0.8814\n",
            "Epoch 16/30\n",
            "11573/11573 [==============================] - 1s 64us/step - loss: 0.3378 - accuracy: 0.8844\n",
            "Epoch 17/30\n",
            "11573/11573 [==============================] - 1s 69us/step - loss: 0.3226 - accuracy: 0.8868\n",
            "Epoch 18/30\n",
            "11573/11573 [==============================] - 1s 71us/step - loss: 0.3117 - accuracy: 0.8951\n",
            "Epoch 19/30\n",
            "11573/11573 [==============================] - 1s 71us/step - loss: 0.3076 - accuracy: 0.8926\n",
            "Epoch 20/30\n",
            "11573/11573 [==============================] - 1s 64us/step - loss: 0.2969 - accuracy: 0.8979\n",
            "Epoch 21/30\n",
            "11573/11573 [==============================] - 1s 65us/step - loss: 0.2835 - accuracy: 0.9050\n",
            "Epoch 22/30\n",
            "11573/11573 [==============================] - 1s 63us/step - loss: 0.2742 - accuracy: 0.9105\n",
            "Epoch 23/30\n",
            "11573/11573 [==============================] - 1s 64us/step - loss: 0.2684 - accuracy: 0.9084\n",
            "Epoch 24/30\n",
            "11573/11573 [==============================] - 1s 64us/step - loss: 0.2569 - accuracy: 0.9130\n",
            "Epoch 25/30\n",
            "11573/11573 [==============================] - 1s 73us/step - loss: 0.2476 - accuracy: 0.9140\n",
            "Epoch 26/30\n",
            "11573/11573 [==============================] - 1s 68us/step - loss: 0.2408 - accuracy: 0.9163\n",
            "Epoch 27/30\n",
            "11573/11573 [==============================] - 1s 64us/step - loss: 0.2363 - accuracy: 0.9180\n",
            "Epoch 28/30\n",
            "11573/11573 [==============================] - 1s 72us/step - loss: 0.2270 - accuracy: 0.9215\n",
            "Epoch 29/30\n",
            "11573/11573 [==============================] - 1s 63us/step - loss: 0.2173 - accuracy: 0.9246\n",
            "Epoch 30/30\n",
            "11573/11573 [==============================] - 1s 66us/step - loss: 0.2101 - accuracy: 0.9282\n",
            "\n",
            "\n",
            "\n",
            "Epoch 1/30\n",
            "11573/11573 [==============================] - 1s 76us/step - loss: 1.7156 - accuracy: 0.4536\n",
            "Epoch 2/30\n",
            "11573/11573 [==============================] - 1s 64us/step - loss: 1.3402 - accuracy: 0.5645\n",
            "Epoch 3/30\n",
            "11573/11573 [==============================] - 1s 68us/step - loss: 1.2018 - accuracy: 0.6127\n",
            "Epoch 4/30\n",
            "11573/11573 [==============================] - 1s 69us/step - loss: 1.1076 - accuracy: 0.6435\n",
            "Epoch 5/30\n",
            "11573/11573 [==============================] - 1s 69us/step - loss: 1.0363 - accuracy: 0.6685\n",
            "Epoch 6/30\n",
            "11573/11573 [==============================] - 1s 67us/step - loss: 0.9861 - accuracy: 0.6829\n",
            "Epoch 7/30\n",
            "11573/11573 [==============================] - 1s 64us/step - loss: 0.9408 - accuracy: 0.6964\n",
            "Epoch 8/30\n",
            "11573/11573 [==============================] - 1s 63us/step - loss: 0.9087 - accuracy: 0.7078\n",
            "Epoch 9/30\n",
            "11573/11573 [==============================] - 1s 64us/step - loss: 0.8763 - accuracy: 0.7172\n",
            "Epoch 10/30\n",
            "11573/11573 [==============================] - 1s 63us/step - loss: 0.8430 - accuracy: 0.7269\n",
            "Epoch 11/30\n",
            "11573/11573 [==============================] - 1s 65us/step - loss: 0.8223 - accuracy: 0.7323\n",
            "Epoch 12/30\n",
            "11573/11573 [==============================] - 1s 69us/step - loss: 0.7954 - accuracy: 0.7452\n",
            "Epoch 13/30\n",
            "11573/11573 [==============================] - 1s 72us/step - loss: 0.7811 - accuracy: 0.7476\n",
            "Epoch 14/30\n",
            "11573/11573 [==============================] - 1s 65us/step - loss: 0.7609 - accuracy: 0.7565\n",
            "Epoch 15/30\n",
            "11573/11573 [==============================] - 1s 65us/step - loss: 0.7465 - accuracy: 0.7583\n",
            "Epoch 16/30\n",
            "11573/11573 [==============================] - 1s 67us/step - loss: 0.7230 - accuracy: 0.7612\n",
            "Epoch 17/30\n",
            "11573/11573 [==============================] - 1s 66us/step - loss: 0.7092 - accuracy: 0.7700\n",
            "Epoch 18/30\n",
            "11573/11573 [==============================] - 1s 65us/step - loss: 0.6864 - accuracy: 0.7779\n",
            "Epoch 19/30\n",
            "11573/11573 [==============================] - 1s 72us/step - loss: 0.6776 - accuracy: 0.7820\n",
            "Epoch 20/30\n",
            "11573/11573 [==============================] - 1s 64us/step - loss: 0.6674 - accuracy: 0.7802\n",
            "Epoch 21/30\n",
            "11573/11573 [==============================] - 1s 65us/step - loss: 0.6503 - accuracy: 0.7870\n",
            "Epoch 22/30\n",
            "11573/11573 [==============================] - 1s 66us/step - loss: 0.6446 - accuracy: 0.7891\n",
            "Epoch 23/30\n",
            "11573/11573 [==============================] - 1s 73us/step - loss: 0.6190 - accuracy: 0.7992\n",
            "Epoch 24/30\n",
            "11573/11573 [==============================] - 1s 66us/step - loss: 0.6139 - accuracy: 0.7982\n",
            "Epoch 25/30\n",
            "11573/11573 [==============================] - 1s 71us/step - loss: 0.6062 - accuracy: 0.7974\n",
            "Epoch 26/30\n",
            "11573/11573 [==============================] - 1s 68us/step - loss: 0.5893 - accuracy: 0.8055\n",
            "Epoch 27/30\n",
            "11573/11573 [==============================] - 1s 65us/step - loss: 0.5758 - accuracy: 0.8083\n",
            "Epoch 28/30\n",
            "11573/11573 [==============================] - 1s 65us/step - loss: 0.5711 - accuracy: 0.8123\n",
            "Epoch 29/30\n",
            "11573/11573 [==============================] - 1s 67us/step - loss: 0.5622 - accuracy: 0.8151\n",
            "Epoch 30/30\n",
            "11573/11573 [==============================] - 1s 67us/step - loss: 0.5489 - accuracy: 0.8178\n",
            "\n",
            "\n",
            "\n",
            "Epoch 1/30\n",
            "8196/8196 [==============================] - 1s 120us/step - loss: 1.6858 - accuracy: 0.4433\n",
            "Epoch 2/30\n",
            "8196/8196 [==============================] - 1s 110us/step - loss: 1.0782 - accuracy: 0.6514\n",
            "Epoch 3/30\n",
            "8196/8196 [==============================] - 1s 112us/step - loss: 0.8100 - accuracy: 0.7389\n",
            "Epoch 4/30\n",
            "8196/8196 [==============================] - 1s 113us/step - loss: 0.6500 - accuracy: 0.7939\n",
            "Epoch 5/30\n",
            "8196/8196 [==============================] - 1s 114us/step - loss: 0.5478 - accuracy: 0.8202\n",
            "Epoch 6/30\n",
            "8196/8196 [==============================] - 1s 110us/step - loss: 0.4613 - accuracy: 0.8536\n",
            "Epoch 7/30\n",
            "8196/8196 [==============================] - 1s 110us/step - loss: 0.3968 - accuracy: 0.8720\n",
            "Epoch 8/30\n",
            "8196/8196 [==============================] - 1s 115us/step - loss: 0.3562 - accuracy: 0.8847\n",
            "Epoch 9/30\n",
            "8196/8196 [==============================] - 1s 112us/step - loss: 0.3062 - accuracy: 0.8968\n",
            "Epoch 10/30\n",
            "8196/8196 [==============================] - 1s 116us/step - loss: 0.2730 - accuracy: 0.9147\n",
            "Epoch 11/30\n",
            "8196/8196 [==============================] - 1s 107us/step - loss: 0.2462 - accuracy: 0.9192\n",
            "Epoch 12/30\n",
            "8196/8196 [==============================] - 1s 115us/step - loss: 0.2319 - accuracy: 0.9235\n",
            "Epoch 13/30\n",
            "8196/8196 [==============================] - 1s 117us/step - loss: 0.2259 - accuracy: 0.9295\n",
            "Epoch 14/30\n",
            "8196/8196 [==============================] - 1s 118us/step - loss: 0.2044 - accuracy: 0.9353\n",
            "Epoch 15/30\n",
            "8196/8196 [==============================] - 1s 109us/step - loss: 0.1608 - accuracy: 0.9463\n",
            "Epoch 16/30\n",
            "8196/8196 [==============================] - 1s 112us/step - loss: 0.1927 - accuracy: 0.9386\n",
            "Epoch 17/30\n",
            "8196/8196 [==============================] - 1s 112us/step - loss: 0.1719 - accuracy: 0.9467\n",
            "Epoch 18/30\n",
            "8196/8196 [==============================] - 1s 112us/step - loss: 0.1432 - accuracy: 0.9513\n",
            "Epoch 19/30\n",
            "8196/8196 [==============================] - 1s 116us/step - loss: 0.1344 - accuracy: 0.9584\n",
            "Epoch 20/30\n",
            "8196/8196 [==============================] - 1s 114us/step - loss: 0.1363 - accuracy: 0.9536\n",
            "Epoch 21/30\n",
            "8196/8196 [==============================] - 1s 114us/step - loss: 0.1442 - accuracy: 0.9518\n",
            "Epoch 22/30\n",
            "8196/8196 [==============================] - 1s 111us/step - loss: 0.1266 - accuracy: 0.9580\n",
            "Epoch 23/30\n",
            "8196/8196 [==============================] - 1s 115us/step - loss: 0.1218 - accuracy: 0.9595\n",
            "Epoch 24/30\n",
            "8196/8196 [==============================] - 1s 117us/step - loss: 0.1178 - accuracy: 0.9671\n",
            "Epoch 25/30\n",
            "8196/8196 [==============================] - 1s 114us/step - loss: 0.0908 - accuracy: 0.9718\n",
            "Epoch 26/30\n",
            "8196/8196 [==============================] - 1s 109us/step - loss: 0.1225 - accuracy: 0.9619\n",
            "Epoch 27/30\n",
            "8196/8196 [==============================] - 1s 110us/step - loss: 0.1249 - accuracy: 0.9613\n",
            "Epoch 28/30\n",
            "8196/8196 [==============================] - 1s 110us/step - loss: 0.0865 - accuracy: 0.9722\n",
            "Epoch 29/30\n",
            "8196/8196 [==============================] - 1s 113us/step - loss: 0.0927 - accuracy: 0.9707\n",
            "Epoch 30/30\n",
            "8196/8196 [==============================] - 1s 111us/step - loss: 0.0752 - accuracy: 0.9765\n",
            "\n",
            "\n",
            "\n",
            "Epoch 1/30\n",
            "12073/12073 [==============================] - 1s 120us/step - loss: 0.9697 - accuracy: 0.7002\n",
            "Epoch 2/30\n",
            "12073/12073 [==============================] - 1s 111us/step - loss: 0.6090 - accuracy: 0.8025\n",
            "Epoch 3/30\n",
            "12073/12073 [==============================] - 1s 105us/step - loss: 0.5090 - accuracy: 0.8348\n",
            "Epoch 4/30\n",
            "12073/12073 [==============================] - 1s 112us/step - loss: 0.4398 - accuracy: 0.8544\n",
            "Epoch 5/30\n",
            "12073/12073 [==============================] - 1s 105us/step - loss: 0.3772 - accuracy: 0.8762\n",
            "Epoch 6/30\n",
            "12073/12073 [==============================] - 1s 113us/step - loss: 0.3397 - accuracy: 0.8877\n",
            "Epoch 7/30\n",
            "12073/12073 [==============================] - 1s 111us/step - loss: 0.3062 - accuracy: 0.9014\n",
            "Epoch 8/30\n",
            "12073/12073 [==============================] - 1s 106us/step - loss: 0.2716 - accuracy: 0.9117\n",
            "Epoch 9/30\n",
            "12073/12073 [==============================] - 1s 111us/step - loss: 0.2442 - accuracy: 0.9175\n",
            "Epoch 10/30\n",
            "12073/12073 [==============================] - 1s 108us/step - loss: 0.2253 - accuracy: 0.9260\n",
            "Epoch 11/30\n",
            "12073/12073 [==============================] - 1s 113us/step - loss: 0.2140 - accuracy: 0.9313\n",
            "Epoch 12/30\n",
            "12073/12073 [==============================] - 1s 107us/step - loss: 0.1758 - accuracy: 0.9404\n",
            "Epoch 13/30\n",
            "12073/12073 [==============================] - 1s 108us/step - loss: 0.1783 - accuracy: 0.9415\n",
            "Epoch 14/30\n",
            "12073/12073 [==============================] - 1s 108us/step - loss: 0.1618 - accuracy: 0.9454\n",
            "Epoch 15/30\n",
            "12073/12073 [==============================] - 1s 108us/step - loss: 0.1515 - accuracy: 0.9472\n",
            "Epoch 16/30\n",
            "12073/12073 [==============================] - 1s 113us/step - loss: 0.1283 - accuracy: 0.9567\n",
            "Epoch 17/30\n",
            "12073/12073 [==============================] - 1s 112us/step - loss: 0.1309 - accuracy: 0.9559\n",
            "Epoch 18/30\n",
            "12073/12073 [==============================] - 1s 112us/step - loss: 0.1215 - accuracy: 0.9572\n",
            "Epoch 19/30\n",
            "12073/12073 [==============================] - 1s 109us/step - loss: 0.1235 - accuracy: 0.9580\n",
            "Epoch 20/30\n",
            "12073/12073 [==============================] - 1s 111us/step - loss: 0.1055 - accuracy: 0.9648\n",
            "Epoch 21/30\n",
            "12073/12073 [==============================] - 1s 107us/step - loss: 0.0962 - accuracy: 0.9680\n",
            "Epoch 22/30\n",
            "12073/12073 [==============================] - 1s 112us/step - loss: 0.0958 - accuracy: 0.9679\n",
            "Epoch 23/30\n",
            "12073/12073 [==============================] - 1s 107us/step - loss: 0.0760 - accuracy: 0.9739\n",
            "Epoch 24/30\n",
            "12073/12073 [==============================] - 1s 115us/step - loss: 0.0927 - accuracy: 0.9709\n",
            "Epoch 25/30\n",
            "12073/12073 [==============================] - 1s 107us/step - loss: 0.0989 - accuracy: 0.9676\n",
            "Epoch 26/30\n",
            "12073/12073 [==============================] - 1s 107us/step - loss: 0.0648 - accuracy: 0.9795\n",
            "Epoch 27/30\n",
            "12073/12073 [==============================] - 1s 109us/step - loss: 0.0830 - accuracy: 0.9717\n",
            "Epoch 28/30\n",
            "12073/12073 [==============================] - 1s 107us/step - loss: 0.0616 - accuracy: 0.9797\n",
            "Epoch 29/30\n",
            "12073/12073 [==============================] - 1s 107us/step - loss: 0.0676 - accuracy: 0.9780\n",
            "Epoch 30/30\n",
            "12073/12073 [==============================] - 1s 108us/step - loss: 0.0806 - accuracy: 0.9719\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Models' scores\n",
            "\n",
            "\n",
            "5184/5184 [==============================] - 0s 35us/step\n",
            "\n",
            "The accuracy for Phone Accel is: 0.8315972089767456\n",
            "\n",
            "5184/5184 [==============================] - 0s 31us/step\n",
            "\n",
            "The accuracy for Phone Gyro is: 0.5048225522041321\n",
            "\n",
            "4960/4960 [==============================] - 0s 34us/step\n",
            "\n",
            "The accuracy for Watch Accel is: 0.8286290168762207\n",
            "\n",
            "4960/4960 [==============================] - 0s 34us/step\n",
            "\n",
            "The accuracy for Watch Gyro is: 0.696169376373291\n",
            "\n",
            "2049/2049 [==============================] - 0s 50us/step\n",
            "\n",
            "The accuracy for Phone is: 0.8530990481376648\n",
            "\n",
            "3019/3019 [==============================] - 0s 44us/step\n",
            "\n",
            "The accuracy for Watch is: 0.8671745657920837\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}