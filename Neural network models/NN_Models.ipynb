{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN-Models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXqRKw6cBJNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !git clone https://github.com/KodeWil/final_project_AI_csv_Data.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tqCXs-QyJKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dependencies\n",
        "# %reset\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense# Neural network\n",
        "import pandas as pd \n",
        "import glob \n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import copy\n",
        "from google.colab import files as fl\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import neural_network\n",
        "import random as rn\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkfC2JCgBiKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def addData(files: str) -> list:\n",
        "    allCsv = []\n",
        "    for file in files:\n",
        "      temp = open(file)\n",
        "      tempDf = pd.read_csv(file)\n",
        "      allCsv.append(tempDf)\n",
        "    return allCsv\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8vk9-1prLxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def printAll(df):\n",
        "  pd.set_option('display.max_rows', None)\n",
        "  print(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPLkK4OkBnOH",
        "colab_type": "code",
        "outputId": "d2b21e9f-3ab8-46b3-d8ad-3f0457dac80a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "frames = []\n",
        "\n",
        "#Create a list ('frames') with four nested lists, one per sensor. \n",
        "#Each nested list have all the samples (DF) for that sensor.\n",
        "%cd /content/final_project_AI_csv_Data/phone/accel\n",
        "files = glob.glob('*.csv')\n",
        "files.sort()\n",
        "frames.append(addData(files))\n",
        "%cd /content/final_project_AI_csv_Data/phone/gyro\n",
        "files = glob.glob('*.csv')\n",
        "files.sort()\n",
        "frames.append(addData(files))\n",
        "%cd /content/final_project_AI_csv_Data/watch/accel\n",
        "files = glob.glob('*.csv')\n",
        "files.sort()\n",
        "frames.append(addData(files))\n",
        "%cd /content/final_project_AI_csv_Data/watch/gyro\n",
        "files = glob.glob('*.csv')\n",
        "files.sort()\n",
        "frames.append(addData(files))\n",
        "print(len(frames))\n",
        "# 0 in frames = /phone/accel\n",
        "# 1 in frames = /phone/gyro\n",
        "# 2 in frames = /watch/accel\n",
        "# 3 in frames = /watch/gyro"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/final_project_AI_csv_Data/phone/accel\n",
            "/content/final_project_AI_csv_Data/phone/gyro\n",
            "/content/final_project_AI_csv_Data/watch/accel\n",
            "/content/final_project_AI_csv_Data/watch/gyro\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orlmj0Bh3vQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cutSamples(frames1, frames2):\n",
        "  for i in range (0,50):\n",
        "    samples1 = frames1[i].shape[0]\n",
        "    samples2 = frames2[i].shape[0]\n",
        "    if(samples1 > samples2):\n",
        "      toDrop = list(range(samples2, samples1))\n",
        "      frames1[i].drop(frames1[i].index[[toDrop]], inplace = True)\n",
        "    elif(samples2 > samples1):\n",
        "      toDrop = list(range(samples1, samples2))\n",
        "      frames2[i].drop(frames2[i].index[[toDrop]], inplace = True) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Muo2VDcleOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kerasSequiential(X, y):\n",
        "  InpDim = X.shape[1]\n",
        "  output = y.shape[1]\n",
        "  model = Sequential()\n",
        "  model.add(Dense(int(InpDim*2), input_dim=InpDim, activation=\"relu\"))\n",
        "  model.add(Dense(64, activation=\"relu\"))\n",
        "  model.add(Dense(output, activation=\"softmax\"))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  history = model.fit(X, y, epochs=30, batch_size=40, verbose=0)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24ySOtTEJ4G1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mlpNN(Xt, yt, Xte, yte):\n",
        "  # activTypes = [\"logistic\", \"tanh\", \"relu\"]\n",
        "  # solverTypes = [\"lbfgs\", \"sgd\", \"adam\"]\n",
        "  activTypes = [\"relu\"]\n",
        "  solverTypes = [\"adam\"]\n",
        "  allModels = []\n",
        "  for activType in activTypes:\n",
        "    for solverType in solverTypes:\n",
        "      clf = neural_network.MLPClassifier(\n",
        "          hidden_layer_sizes = [100,64,18],\n",
        "          activation = activType,\n",
        "          solver = solverType,\n",
        "          alpha = 0.0001, # regularización, para la generalización del clasificador\n",
        "          batch_size = 'auto',\n",
        "          learning_rate_init = 0.001,\n",
        "          power_t = 0.5,\n",
        "          max_iter = 300,\n",
        "          shuffle = True,\n",
        "          verbose = False\n",
        "          )\n",
        "      allModels.append((clf, activType, solverType))\n",
        "  best = 0\n",
        "  bestIndex = -1\n",
        "  for i, mlpModel in enumerate(allModels):\n",
        "    mlpModel[0].fit(Xt, yt)\n",
        "    y_predicho = mlpModel[0].predict(Xte)\n",
        "    tempScore = accuracy_score(yte,y_predicho)\n",
        "    if(tempScore > best):\n",
        "      best = tempScore\n",
        "      bestIndex = i\n",
        "  activ = allModels[i][1]\n",
        "  solve = allModels[i][2]\n",
        "  print(\"\")\n",
        "  print(\"Scikit learn multilayer perceptron\")\n",
        "  print(\"\")\n",
        "  print(\"The best mlp's scikit learn model use activation as parameter \" + activ + \" as solver use \" + solve + \" and the accuracy score is : \"+ str(best))\n",
        "  print(\"\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip3zLapcEi03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Split into train and test data, encode \"ACTIVITY\" column into a numerical column\n",
        "def dataTransformation(frame, columns: bool):\n",
        "  ohe = OneHotEncoder()\n",
        "  sc = StandardScaler()\n",
        "  if(columns):\n",
        "    y = frame[\"ACTIVITY\"]\n",
        "    X = frame.drop(columns = [\"ACTIVITY\", \"class\"])\n",
        "    X = X.values\n",
        "    X = sc.fit_transform(X)\n",
        "    y = y.values\n",
        "    y = y.reshape(-1,1)\n",
        "    y = ohe.fit_transform(y).toarray()\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "    return (kerasSequiential(X_train, y_train), X_test, y_test)\n",
        "  else:\n",
        "    y = frame[0]\n",
        "    y = y.values\n",
        "    y = y.reshape(-1,1)\n",
        "    y = ohe.fit_transform(y).toarray()\n",
        "    X = frame.drop(columns = [0,91,93,182])\n",
        "    X = X.values\n",
        "    X = sc.fit_transform(X)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "    mlpNN(X_train, y_train, X_test, y_test)\n",
        "    return (kerasSequiential(X_train, y_train), X_test, y_test)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP0Z_SJEBvmf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        },
        "outputId": "cdbd8e5a-9bd9-418a-bb53-a3d7d1fe216b"
      },
      "source": [
        "#Apply the models to some individuals samples \n",
        "scores = []\n",
        "names = [\"Phone Accel\", \"Phone Gyro\" , \"Watch Accel\", \"Watch Gyro\"]\n",
        "numSamples = 10\n",
        "for frame in frames:\n",
        "  tempAvgScore = 0\n",
        "  for i in range(0,numSamples):\n",
        "    tempVal = rn.randint(0,49)\n",
        "    tempModel = dataTransformation(frame[tempVal], True)\n",
        "    score, acc = tempModel[0].evaluate(tempModel[1], tempModel[2],\n",
        "                            batch_size=20, verbose=0)\n",
        "    tempAvgScore += acc\n",
        "  \n",
        "  scores.append(tempAvgScore/numSamples)\n",
        "print(\"\")\n",
        "print(\"Using \" + str(numSamples) + \" samples (individual measurements) of each sensor \" )\n",
        "print(\"\")\n",
        "for i,name in enumerate(names):\n",
        "  print(\"\")\n",
        "  print(\"The average accuracy score for \" + name + \" is: \" + str(scores[i]))\n",
        "  print(\"\")  \n",
        "\n",
        "# Concatenate all phone Dataframes in a single One\n",
        "sensors = []\n",
        "phoneAccel = pd.concat(frames[0])\n",
        "sensors.append(phoneAccel)\n",
        "phoneGyro = pd.concat(frames[1])\n",
        "sensors.append(phoneGyro)\n",
        "watchAccel = pd.concat(frames[2])\n",
        "sensors.append(watchAccel)\n",
        "watchGyro = pd.concat(frames[3])\n",
        "sensors.append(watchGyro)\n",
        "\n",
        "\n",
        "#Cut samples to match with the number of samples in the other sensor (accel and gyro)\n",
        "cutSamples(frames[0], frames[1]) #Phone sensors\n",
        "cutSamples(frames[2], frames[3]) #Watch sensors\n",
        "\n",
        "#Concat all individual samples for a single sensor in one data frame. \n",
        "phoneAccel = pd.concat(frames[0], ignore_index=True)\n",
        "phoneGyro = pd.concat(frames[1], ignore_index=True)\n",
        "watchAccel = pd.concat(frames[2], ignore_index=True)\n",
        "watchGyro = pd.concat(frames[3], ignore_index=True)\n",
        "\n",
        "#Create a new data frame with both sensors for both devices.\n",
        "phone = pd.concat([phoneAccel, phoneGyro], ignore_index=True, axis = 1)\n",
        "phoneIndex = phone[phone[0] != phone[93]].index\n",
        "phone.drop(phoneIndex, inplace=True)\n",
        "watch = pd.concat([watchAccel, watchGyro], ignore_index=True, axis = 1)\n",
        "watchIndex = watch[watch[0] != watch[93]].index\n",
        "watch.drop(watchIndex, inplace=True)\n",
        "\n",
        "models = []\n",
        "# for sensor in sensors:\n",
        "#   models.append(dataTransformation(sensor, True))\n",
        "print(\"\")\n",
        "print(\"Phone merged sensors accuracy\")\n",
        "print(\"\")\n",
        "models.append(dataTransformation(phone, False))\n",
        "print(\"\")\n",
        "print(\"Watch merged sensors accuracy\")\n",
        "print(\"\")\n",
        "models.append(dataTransformation(watch, False))\n",
        "\n",
        "# names = [\"Phone Accel\", \"Phone Gyro\" , \"Watch Accel\", \"Watch Gyro\", \"Phone\", \"Watch\" ]\n",
        "# print(\"\")\n",
        "print(\"Models' scores\")\n",
        "print(\"\")\n",
        "\n",
        "for i, model in  enumerate(models):\n",
        "  score, acc = model[0].evaluate(model[1], model[2],\n",
        "                            batch_size=20, verbose=0)\n",
        "  print(\"\")\n",
        "  print(\"The accuracy for \" + names[i]+ \" is: \" + str(acc))\n",
        "  print(\"\")\n"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using 10 samples (individual measurements) of each sensor \n",
            "\n",
            "\n",
            "The average accuracy score for Phone Accel is: 0.9291931927204132\n",
            "\n",
            "\n",
            "The average accuracy score for Phone Gyro is: 0.7389419198036193\n",
            "\n",
            "\n",
            "The average accuracy score for Watch Accel is: 0.8990736722946167\n",
            "\n",
            "\n",
            "The average accuracy score for Watch Gyro is: 0.8066042840480805\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py:3940: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  result = getitem(key)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Phone merged sensors accuracy\n",
            "\n",
            "\n",
            "Scikit learn multilayer perceptron\n",
            "\n",
            "The best mlp's scikit learn model use activation as parameter relu as solver use adam and the accuracy score is : 0.7642752562225475\n",
            "\n",
            "\n",
            "Watch merged sensors accuracy\n",
            "\n",
            "\n",
            "Scikit learn multilayer perceptron\n",
            "\n",
            "The best mlp's scikit learn model use activation as parameter relu as solver use adam and the accuracy score is : 0.7976151043391851\n",
            "\n",
            "Models' scores\n",
            "\n",
            "\n",
            "The accuracy for Phone Accel is: 0.8696925044059753\n",
            "\n",
            "\n",
            "The accuracy for Phone Gyro is: 0.8668433427810669\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}